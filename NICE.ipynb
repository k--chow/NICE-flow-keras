{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import imageio\n",
    "\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "#import tensorflow_probability as tfp\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "# Dependency imports\n",
    "from absl import app\n",
    "from absl import flags\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import figure  # pylint: disable=g-import-not-at-top\n",
    "from matplotlib.backends import backend_agg\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout,Layer\n",
    "from tensorflow.keras.layers import Lambda, Concatenate, BatchNormalization, Activation, ZeroPadding2D,LeakyReLU,UpSampling2D, Conv2D,Add, LayerNormalization\n",
    "from tensorflow.keras.layers import Cropping2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from functools import partial\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "from random import choice\n",
    "\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformationLayer(Layer):\n",
    "    def __init__(self, layers=6, dim=392):\n",
    "        super(TransformationLayer, self).__init__()\n",
    "        self.dense_layers = [Dense(1000, activation=LeakyReLU(alpha=0.1)) for _ in range(layers-1)]\n",
    "        self.final = Dense(dim, activation=LeakyReLU(alpha=0.1))\n",
    "        self.layers = layers\n",
    "    def call(self, inputs):\n",
    "        output = inputs\n",
    "        for dense in self.dense_layers:\n",
    "            output = dense(output)\n",
    "        output = self.final(output)\n",
    "        return output\n",
    " \n",
    "class CoupleLayer(Layer):\n",
    "    def __init__(self, transform_layer):\n",
    "        super(CoupleLayer, self).__init__()\n",
    "        self.m = transform_layer\n",
    "    def call(self, inputs):\n",
    "        y1 = inputs[0]\n",
    "        y2 = inputs[1] + inputs[2] #x2 + mx1\n",
    "        return y1, y2\n",
    "    def inverse(self, inputs):\n",
    "        x1 = inputs[0]\n",
    "        x2 = inputs[1] - inputs[2] #x2 + mx1\n",
    "        return x1, x2\n",
    "\n",
    "class SplitLayer(Layer):\n",
    "    def __init__(self, dim=784):\n",
    "        super(SplitLayer, self).__init__()\n",
    "        self.cutoff = int(dim/2)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return inputs[:, :self.cutoff], inputs[:, self.cutoff:]\n",
    "    def inverse(self, inputs):\n",
    "        output = K.concatenate([inputs[0], inputs[1]], axis=1)\n",
    "        return output\n",
    "    \n",
    "class ConcatLayer(Layer):\n",
    "    def __init__(self, dim):\n",
    "        super(ConcatLayer, self).__init__()\n",
    "        self.cutoff = int(dim/2)\n",
    "    def call(self, inputs):\n",
    "        output = K.concatenate([inputs[0], inputs[1]], axis=1)\n",
    "        return output\n",
    "    def inverse(self, inputs):\n",
    "        return inputs[:, :self.cutoff], inputs[:, self.cutoff:]\n",
    "    \n",
    "class PartitionLayer(Layer):\n",
    "    def __init__(self, part_mode='even_odd', orientation=0):\n",
    "        super(PartitionLayer, self).__init__()\n",
    "        self.idx = None\n",
    "        self.part_mode = part_mode\n",
    "        self.orientation= orientation\n",
    "    def call(self, inputs):\n",
    "        dim = K.int_shape(inputs)[-1]\n",
    "        if self.idx == None:\n",
    "            self.idx = list(range(dim))\n",
    "            if self.part_mode == 'reverse':\n",
    "                self.idx = self.idx[::-1]\n",
    "            elif self.part_mode == 'random':\n",
    "                np.random.shuffle(self.idx)\n",
    "            elif self.part_mode=='even_odd':\n",
    "                self.idx = np.array(self.idx)\n",
    "                temp = np.reshape(self.idx, (int(dim/2), 2)) \n",
    "                left = temp[:,0]\n",
    "                right = temp[:,1]\n",
    "                if self.orientation == 1:\n",
    "                    self.idx = list(np.append(left, right))\n",
    "                else:\n",
    "                    self.idx = list(np.append(right, left))\n",
    "        inputs = K.transpose(inputs)\n",
    "        outputs = K.gather(inputs, self.idx)\n",
    "        outputs = K.transpose(outputs)\n",
    "        return outputs\n",
    "    def inverse(self, inputs):\n",
    "        dim = len(self.idx)\n",
    "        _ = sorted(zip(range(dim), self.idx), key=lambda s: s[1])\n",
    "        reverse_idx = [i[0] for i in _]\n",
    "        inputs = K.transpose(inputs)\n",
    "        outputs = K.gather(inputs, reverse_idx)\n",
    "        outputs = K.transpose(outputs)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class ScaleLayer(Layer): # Hadamard product\n",
    "    def __init__(self):\n",
    "        super(ScaleLayer, self).__init__()\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(name='kernel', shape=input_shape[1:], initializer='uniform', trainable=True)\n",
    "        #super(ScaleLayer, self).build(input_shape)\n",
    "    def call(self, inputs):\n",
    "        self.add_loss(-1*K.sum(scale.kernel))\n",
    "        return inputs*K.exp(self.kernel)\n",
    "    def inverse(self, inputs):\n",
    "        return inputs*K.exp(-self.kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# reshape into 1 dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(x_train)\n",
    "x_train_reshaped = x_train.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_reshaped = np.reshape(x_train_reshaped, (60000, 28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NICE():\n",
    "    def __init__(self, coupling_layers=4, prior='logistic', total_dim=784, img_dim=(28,28)):\n",
    "        # prior loss\n",
    "        self.prior = prior\n",
    "        self.total_dim = total_dim\n",
    "        self.img_dim = img_dim\n",
    "        self.split = SplitLayer(dim=self.total_dim)\n",
    "        # layers into boy\n",
    "        # keep a functional version too. Makes sense to me.\n",
    "        self.transform1 = TransformationLayer()\n",
    "        self.transform2 = TransformationLayer()\n",
    "        self.transform3 = TransformationLayer()\n",
    "        self.transform4 = TransformationLayer()\n",
    "\n",
    "        self.couple1 = CoupleLayer(self.transform1)\n",
    "        self.couple2 = CoupleLayer(self.transform2)\n",
    "        self.couple3 = CoupleLayer(self.transform3)\n",
    "        self.couple4 = CoupleLayer(self.transform4)\n",
    "\n",
    "        self.concat = ConcatLayer()\n",
    "        self.scale = ScaleLayer()\n",
    "        self.partition1 = PartitionLayer(orientation=1, part_mode='even_odd')\n",
    "        self.partition2 = PartitionLayer(orientation=0)\n",
    "        self.partition3 = PartitionLayer(orientation=1)\n",
    "        self.partition4 = PartitionLayer(orientation=0)\n",
    "        \n",
    "        self.partial_scale_loss = partial(self.scale_loss, scale=self.scale)\n",
    "        self.partial_scale_loss.__name__ = \"scale\"\n",
    "\n",
    "        partial_total_loss = partial(total_loss, scale=self.scale)\n",
    "        partial_total_loss.__name__ = 'total'\n",
    "\n",
    "        optimizer = tf.keras.optimizers.Adam(lr=0.0001, epsilon=1e-4, beta_2=0.01)\n",
    "        self.encoder = self.build_encoder()\n",
    "        # this shit broke as fuck, be careful\n",
    "        encoder.compile(loss = [self.ml_loss, self.scale_loss], optimizer=optimizer, metrics=[ml_loss, self.partial_scale_loss], loss_weights=[1, 1])\n",
    "        #encoder.compile(loss = partial_total_loss, optimizer=optimizer, metrics=[partial_total_loss, ml_loss, self.partial_scale_loss])\n",
    "        #encoder.compile(loss = ml_loss, optimizer=optimizer, metrics=[partial_total_loss, ml_loss, self.partial_scale_loss])\n",
    "        self.decoder = None # initialize after training\n",
    "        \n",
    "    def build_encoder(self):\n",
    "        img_shape = (28*28)\n",
    "        img = Input(shape=(28*28))\n",
    "        #img2 = Lambda(lambda s: K.in_train_phase(s-0.01*K.random_uniform(K.shape(s)), s))(img)\n",
    "        # self.partition\n",
    "        # self.split in half = x1 x2\n",
    "        partitiond = self.partition1(img)\n",
    "        x1, x2 = self.split(partitiond)\n",
    "        # do a self.transform\n",
    "        mx1 = self.transform1(x1)\n",
    "        # self.couple x2 + m*(x1)\n",
    "        y1, y2 = self.couple1([x1, x2, mx1])\n",
    "        y = self.concat([y1, y2])\n",
    "\n",
    "        y = self.partition2(y)\n",
    "        x1, x2 = self.split(y)\n",
    "        # do a self.transform\n",
    "        mx1 = self.transform2(x1)\n",
    "        # self.couple x2 + m*(x1)\n",
    "        y1, y2 = self.couple2([x1, x2, mx1])\n",
    "        y = self.concat([y1, y2])\n",
    "\n",
    "        y = self.partition3(y)\n",
    "        x1, x2 = self.split(y)\n",
    "        # do a self.transform\n",
    "        mx1 = self.transform3(x1)\n",
    "        # self.couple x2 + m*(x1)\n",
    "        y1, y2 = self.couple3([x1, x2, mx1])\n",
    "        y = self.concat([y1, y2])\n",
    "\n",
    "        y = self.partition4(y)\n",
    "        x1, x2 = self.split(y)\n",
    "        # do a self.transform\n",
    "        mx1 = self.transform4(x1)\n",
    "        # self.couple x2 + m*(x1)\n",
    "        y1, y2 = self.couple4([x1, x2, mx1])\n",
    "        y = self.concat([y1, y2])\n",
    "        y = self.scale(y)\n",
    "\n",
    "        # don't forget the loss of the self.scale\n",
    "        encoder = Model([img], [y])\n",
    "        encoder.summary()\n",
    "        return encoder\n",
    "    \n",
    "    def scale_loss(self, y_true, y_pred, scale): \n",
    "        return -1*K.sum(self.scale.kernel)\n",
    "    \n",
    "    def ml_loss(self, y_true, y_pred):\n",
    "        loss = None\n",
    "        if self.prior == 'gaussian':\n",
    "            loss = K.sum(0.5 * y_pred**2, 1)\n",
    "        elif self.prior == 'logistic':\n",
    "            loss = K.sum ( K.softplus(y_pred) + K.softplus(-y_pred), axis=1 )\n",
    "        return loss\n",
    "\n",
    "    def total_loss(self, y_true, y_pred, scale):\n",
    "        return self.ml_loss(y_true, y_pred) + self.scale_loss(y_true, y_pred, self.scale)\n",
    "\n",
    "    def train(self, x_train, batch_size=256, epochs=10):\n",
    "        encoder.fit(x_train, x_train, batch_size=batch_size, epochs=epochs, verbose=2)\n",
    "\n",
    "    def build_decoder(self):\n",
    "        latent = Input(shape=(self.total_dim))\n",
    "        sample_inversed = self.scale.inverse(latent)\n",
    "\n",
    "        y1, y2 = self.concat.inverse(sample_inversed)\n",
    "        my1 = self.transform4(y1)\n",
    "        x1, x2 = self.couple4.inverse([y1, y2, my1]) \n",
    "        x = self.split.inverse([x1, x2])\n",
    "        x = self.partition4.inverse(x)\n",
    "\n",
    "        y1, y2 = self.concat.inverse(x)\n",
    "        my1 = self.transform3(y1)\n",
    "        x1, x2 = self.couple3.inverse([y1, y2, my1]) \n",
    "        x = self.split.inverse([x1, x2])\n",
    "        x = self.partition3.inverse(x)\n",
    "\n",
    "        y1, y2 = self.concat.inverse(x)\n",
    "        my1 = self.transform2(y1)\n",
    "        x1, x2 = self.couple2.inverse([y1, y2, my1]) \n",
    "        x = self.split.inverse([x1, x2])\n",
    "        x = self.partition2.inverse(x)\n",
    "\n",
    "        y1, y2 = self.concat.inverse(x)\n",
    "        my1 = self.transform1(y1)\n",
    "        x1, x2 = self.couple1.inverse([y1, y2, my1]) \n",
    "        x = self.split.inverse([x1, x2])\n",
    "        x = self.partition1.inverse(x)\n",
    "\n",
    "        decoder = Model([latent], [x])\n",
    "        decoder.summary()\n",
    "        self.decoder = decoder\n",
    "    def sample(self, noise):\n",
    "        if self.decoder:\n",
    "            return self.decoder(noise)\n",
    "        return None\n",
    "    \n",
    "    def sample_to_file(self, rows):\n",
    "        figure = np.zeros((self.img_size[0] * n, self.img_size[0] * n))\n",
    "        \n",
    "        for i in range(rows):\n",
    "            for j in range(rows):\n",
    "                z_sample = np.array(np.random.randn(1, self.total_dim)) * 0.75\n",
    "                x_decoded = decoder.predict(z_sample)\n",
    "                digit = x_decoded[0].reshape(self.img_size[0], self.img_size[0])\n",
    "                figure[i * self.img_size[0]: (i + 1) * self.img_size[0],\n",
    "                       j * self.img_size[0]: (j + 1) * self.img_size[0]] = digit\n",
    "\n",
    "        figure = np.clip(figure*255, 0, 255)\n",
    "        imageio.imwrite('test.png', figure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           [(None, 784)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "partition_layer_41 (PartitionLa (None, 784)          0           input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "split_layer_17 (SplitLayer)     ((None, 392), (None, 0           partition_layer_41[0][0]         \n",
      "                                                                 partition_layer_42[0][0]         \n",
      "                                                                 partition_layer_43[0][0]         \n",
      "                                                                 partition_layer_44[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "transformation_layer_60 (Transf (None, 392)          4789392     split_layer_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "couple_layer_56 (CoupleLayer)   ((None, 392), (None, 4789392     split_layer_17[0][0]             \n",
      "                                                                 split_layer_17[0][1]             \n",
      "                                                                 transformation_layer_60[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer_14 (ConcatLayer)   (None, 784)          0           couple_layer_56[0][0]            \n",
      "                                                                 couple_layer_56[0][1]            \n",
      "                                                                 couple_layer_57[0][0]            \n",
      "                                                                 couple_layer_57[0][1]            \n",
      "                                                                 couple_layer_58[0][0]            \n",
      "                                                                 couple_layer_58[0][1]            \n",
      "                                                                 couple_layer_59[0][0]            \n",
      "                                                                 couple_layer_59[0][1]            \n",
      "__________________________________________________________________________________________________\n",
      "partition_layer_42 (PartitionLa (None, 784)          0           concat_layer_14[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "transformation_layer_61 (Transf (None, 392)          4789392     split_layer_17[1][0]             \n",
      "__________________________________________________________________________________________________\n",
      "couple_layer_57 (CoupleLayer)   ((None, 392), (None, 4789392     split_layer_17[1][0]             \n",
      "                                                                 split_layer_17[1][1]             \n",
      "                                                                 transformation_layer_61[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "partition_layer_43 (PartitionLa (None, 784)          0           concat_layer_14[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "transformation_layer_62 (Transf (None, 392)          4789392     split_layer_17[2][0]             \n",
      "__________________________________________________________________________________________________\n",
      "couple_layer_58 (CoupleLayer)   ((None, 392), (None, 4789392     split_layer_17[2][0]             \n",
      "                                                                 split_layer_17[2][1]             \n",
      "                                                                 transformation_layer_62[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "partition_layer_44 (PartitionLa (None, 784)          0           concat_layer_14[2][0]            \n",
      "__________________________________________________________________________________________________\n",
      "transformation_layer_63 (Transf (None, 392)          4789392     split_layer_17[3][0]             \n",
      "__________________________________________________________________________________________________\n",
      "couple_layer_59 (CoupleLayer)   ((None, 392), (None, 4789392     split_layer_17[3][0]             \n",
      "                                                                 split_layer_17[3][1]             \n",
      "                                                                 transformation_layer_63[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "scale_layer_14 (ScaleLayer)     (None, 784)          784         concat_layer_14[3][0]            \n",
      "==================================================================================================\n",
      "Total params: 19,158,352\n",
      "Trainable params: 19,158,352\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nice = NICE()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If our model works, it should perfectly return an input sample, even before training,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           [(None, 784)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_4 (TensorFlowOp [(None, 784)]        0           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_26 (T [(None, 392)]        0           tf_op_layer_Mul_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_27 (T [(None, 392)]        0           tf_op_layer_Mul_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "transformation_layer_63 (Transf (None, 392)          4789392     tf_op_layer_strided_slice_26[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_13 (TensorFlowO [(None, 392)]        0           tf_op_layer_strided_slice_27[0][0\n",
      "                                                                 transformation_layer_63[3][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_13 (TensorFl [(None, 784)]        0           tf_op_layer_strided_slice_26[0][0\n",
      "                                                                 tf_op_layer_Sub_13[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_24 (Tenso [(784, None)]        0           tf_op_layer_concat_13[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_12 (Tensor [(784, None)]        0           tf_op_layer_Transpose_24[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_25 (Tenso [(None, 784)]        0           tf_op_layer_GatherV2_12[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_28 (T [(None, 392)]        0           tf_op_layer_Transpose_25[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_29 (T [(None, 392)]        0           tf_op_layer_Transpose_25[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "transformation_layer_62 (Transf (None, 392)          4789392     tf_op_layer_strided_slice_28[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_14 (TensorFlowO [(None, 392)]        0           tf_op_layer_strided_slice_29[0][0\n",
      "                                                                 transformation_layer_62[3][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_14 (TensorFl [(None, 784)]        0           tf_op_layer_strided_slice_28[0][0\n",
      "                                                                 tf_op_layer_Sub_14[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_26 (Tenso [(784, None)]        0           tf_op_layer_concat_14[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_13 (Tensor [(784, None)]        0           tf_op_layer_Transpose_26[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_27 (Tenso [(None, 784)]        0           tf_op_layer_GatherV2_13[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_30 (T [(None, 392)]        0           tf_op_layer_Transpose_27[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_31 (T [(None, 392)]        0           tf_op_layer_Transpose_27[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "transformation_layer_61 (Transf (None, 392)          4789392     tf_op_layer_strided_slice_30[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_15 (TensorFlowO [(None, 392)]        0           tf_op_layer_strided_slice_31[0][0\n",
      "                                                                 transformation_layer_61[3][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_15 (TensorFl [(None, 784)]        0           tf_op_layer_strided_slice_30[0][0\n",
      "                                                                 tf_op_layer_Sub_15[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_28 (Tenso [(784, None)]        0           tf_op_layer_concat_15[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_14 (Tensor [(784, None)]        0           tf_op_layer_Transpose_28[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_29 (Tenso [(None, 784)]        0           tf_op_layer_GatherV2_14[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_32 (T [(None, 392)]        0           tf_op_layer_Transpose_29[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_33 (T [(None, 392)]        0           tf_op_layer_Transpose_29[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "transformation_layer_60 (Transf (None, 392)          4789392     tf_op_layer_strided_slice_32[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_16 (TensorFlowO [(None, 392)]        0           tf_op_layer_strided_slice_33[0][0\n",
      "                                                                 transformation_layer_60[3][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_16 (TensorFl [(None, 784)]        0           tf_op_layer_strided_slice_32[0][0\n",
      "                                                                 tf_op_layer_Sub_16[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_30 (Tenso [(784, None)]        0           tf_op_layer_concat_16[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_15 (Tensor [(784, None)]        0           tf_op_layer_Transpose_30[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_31 (Tenso [(None, 784)]        0           tf_op_layer_GatherV2_15[0][0]    \n",
      "==================================================================================================\n",
      "Total params: 19,157,568\n",
      "Trainable params: 19,157,568\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nice.build_decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff4f01653d0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.reshape(x_train_reshaped[0]*255, (28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           [(None, 784)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_3 (TensorFlowOp [(None, 784)]        0           input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_18 (T [(None, 392)]        0           tf_op_layer_Mul_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_19 (T [(None, 392)]        0           tf_op_layer_Mul_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "transformation_layer_63 (Transf (None, 392)          4789392     tf_op_layer_strided_slice_18[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_9 (TensorFlowOp [(None, 392)]        0           tf_op_layer_strided_slice_19[0][0\n",
      "                                                                 transformation_layer_63[2][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_9 (TensorFlo [(None, 784)]        0           tf_op_layer_strided_slice_18[0][0\n",
      "                                                                 tf_op_layer_Sub_9[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_16 (Tenso [(784, None)]        0           tf_op_layer_concat_9[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_8 (TensorF [(784, None)]        0           tf_op_layer_Transpose_16[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_17 (Tenso [(None, 784)]        0           tf_op_layer_GatherV2_8[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_20 (T [(None, 392)]        0           tf_op_layer_Transpose_17[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_21 (T [(None, 392)]        0           tf_op_layer_Transpose_17[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "transformation_layer_62 (Transf (None, 392)          4789392     tf_op_layer_strided_slice_20[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_10 (TensorFlowO [(None, 392)]        0           tf_op_layer_strided_slice_21[0][0\n",
      "                                                                 transformation_layer_62[2][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_10 (TensorFl [(None, 784)]        0           tf_op_layer_strided_slice_20[0][0\n",
      "                                                                 tf_op_layer_Sub_10[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_18 (Tenso [(784, None)]        0           tf_op_layer_concat_10[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_9 (TensorF [(784, None)]        0           tf_op_layer_Transpose_18[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_19 (Tenso [(None, 784)]        0           tf_op_layer_GatherV2_9[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_22 (T [(None, 392)]        0           tf_op_layer_Transpose_19[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_23 (T [(None, 392)]        0           tf_op_layer_Transpose_19[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "transformation_layer_61 (Transf (None, 392)          4789392     tf_op_layer_strided_slice_22[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_11 (TensorFlowO [(None, 392)]        0           tf_op_layer_strided_slice_23[0][0\n",
      "                                                                 transformation_layer_61[2][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_11 (TensorFl [(None, 784)]        0           tf_op_layer_strided_slice_22[0][0\n",
      "                                                                 tf_op_layer_Sub_11[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_20 (Tenso [(784, None)]        0           tf_op_layer_concat_11[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_10 (Tensor [(784, None)]        0           tf_op_layer_Transpose_20[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_21 (Tenso [(None, 784)]        0           tf_op_layer_GatherV2_10[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_24 (T [(None, 392)]        0           tf_op_layer_Transpose_21[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_25 (T [(None, 392)]        0           tf_op_layer_Transpose_21[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "transformation_layer_60 (Transf (None, 392)          4789392     tf_op_layer_strided_slice_24[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_12 (TensorFlowO [(None, 392)]        0           tf_op_layer_strided_slice_25[0][0\n",
      "                                                                 transformation_layer_60[2][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_12 (TensorFl [(None, 784)]        0           tf_op_layer_strided_slice_24[0][0\n",
      "                                                                 tf_op_layer_Sub_12[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_22 (Tenso [(784, None)]        0           tf_op_layer_concat_12[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_11 (Tensor [(784, None)]        0           tf_op_layer_Transpose_22[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose_23 (Tenso [(None, 784)]        0           tf_op_layer_GatherV2_11[0][0]    \n",
      "==================================================================================================\n",
      "Total params: 19,157,568\n",
      "Trainable params: 19,157,568\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff4e07a7690>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = nice.encoder(x_train_reshaped[0:1])\n",
    "plt.imshow(np.reshape(nice.sample(sample)[0]*255, (28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kchow/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 - 2s - loss: 1090.0120 - ml_loss: 1100.6116 - scale: 0.6713\n",
      "Epoch 2/10\n",
      "235/235 - 2s - loss: 1067.2042 - ml_loss: 1096.2172 - scale: 0.6713\n",
      "Epoch 3/10\n",
      "235/235 - 2s - loss: 1047.5137 - ml_loss: 1094.9469 - scale: 0.6713\n",
      "Epoch 4/10\n",
      "235/235 - 2s - loss: 1028.5917 - ml_loss: 1094.4462 - scale: 0.6713\n",
      "Epoch 5/10\n",
      "235/235 - 2s - loss: 1009.9269 - ml_loss: 1094.2032 - scale: 0.6713\n",
      "Epoch 6/10\n",
      "235/235 - 2s - loss: 991.3970 - ml_loss: 1094.0959 - scale: 0.6713\n",
      "Epoch 7/10\n",
      "235/235 - 2s - loss: 972.9176 - ml_loss: 1094.0382 - scale: 0.6713\n",
      "Epoch 8/10\n",
      "235/235 - 2s - loss: 954.5137 - ml_loss: 1094.0574 - scale: 0.6713\n",
      "Epoch 9/10\n",
      "235/235 - 2s - loss: 936.1445 - ml_loss: 1094.1100 - scale: 0.6713\n",
      "Epoch 10/10\n",
      "235/235 - 2s - loss: 917.8488 - ml_loss: 1094.2375 - scale: 0.6713\n"
     ]
    }
   ],
   "source": [
    "nice.train(x_train_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff4e04be590>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples = np.random.randn(10, 28*28)*0.75\n",
    "samples = nice.sample(samples)\n",
    "plt.imshow(np.reshape(samples[1]*255, (28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
